{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic EDA using `YData Profiling`\n",
    "\n",
    "**Author Name:** Danish Azeem\\\n",
    "**Email:** danishazeem365@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Assighnment: Names of 5 0r 8 libraries that can use y-data profiling to data analysis\n",
    "\n",
    " There are several libraries available in Python that can help automate the process of Exploratory Data Analysis (EDA) and provide comprehensive reports with visualizations and insights. Some popular libraries for automatic EDA include:\n",
    "\n",
    "1. **Pandas Profiling**: Pandas Profiling is a Python library that generates interactive HTML reports containing descriptive statistics, visualizations, and correlation matrices for a given dataset. It provides a quick overview of the data distribution, missing values, correlations, and more.\n",
    "\n",
    "2. **AutoViz**: AutoViz is an automatic visualization library that generates a wide variety of plots for each feature in the dataset. It automatically selects the appropriate chart type based on the data type and distribution of each feature.\n",
    "\n",
    "3. **Sweetviz**: Sweetviz is a Python library for visualizing and comparing datasets. It generates detailed comparative reports with statistics, visualizations, and insights for both individual features and feature interactions.\n",
    "\n",
    "4. **DataPrep**: DataPrep is a Python library that simplifies the data preparation and EDA process. It provides functions for data cleaning, visualization, profiling, and feature engineering tasks.\n",
    "\n",
    "5. **D-Tale**: D-Tale is a Flask-based tool that generates interactive web-based reports for EDA. It allows users to explore datasets, visualize data distributions, and analyze data relationships using an intuitive interface.\n",
    "\n",
    "These libraries can help streamline the process of Exploratory Data Analysis by automating routine tasks and providing actionable insights to analysts and data scientists. You can choose the library that best fits your requirements and preferences for conducting EDA on your datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**1. Pandas Profiling (replaced by YData Profiling):**\n",
    "\n",
    "While Pandas Profiling is no longer actively maintained, its successor, YData Profiling (formerly Pandas Profiling), offers a user-friendly and comprehensive approach to automated EDA. It generates an interactive HTML report summarizing data types, missing values, distributions, correlations, and more.\n",
    "\n",
    "**2. Dtale:**\n",
    "\n",
    "Dtale is another excellent library for interactive EDA. It focuses on providing visualizations within a web application interface, allowing you to explore data distributions, correlations, and filter data points intuitively.\n",
    "\n",
    "**3. Sweetviz:**\n",
    "\n",
    "Sweetviz is another user-friendly library that generates a visual and interactive HTML report for your data. It offers various charts and summaries to explore data distributions, missing values, relationships between variables, and more.\n",
    "\n",
    "**4. AutoViz:**\n",
    "\n",
    "AutoViz is a lightweight library that automatically generates various visualizations for your data, including histograms, scatter plots, box plots, and heatmaps. It's a good option for quickly getting a visual overview of your data.\n",
    "\n",
    "**5. ExploriPy:**\n",
    "\n",
    "ExploriPy focuses on providing statistical summaries and tests alongside visualizations. It can be helpful for identifying potential outliers, normality checks, and exploring relationships between variables through tests like ANOVA and Chi-Square.\n",
    "\n",
    "**Choosing the Right Library:**\n",
    "\n",
    "The best library for you depends on your specific needs and preferences. Consider these factors:\n",
    "\n",
    "- **Desired level of automation:** Do you want a comprehensive report like YData Profiling or a focus on specific visualizations like AutoViz?\n",
    "- **Interactivity:** Do you prefer interactive exploration within a web app (Dtale) or a static HTML report (YData Profiling, Sweetviz)?\n",
    "- **Statistical tests:** If you need statistical summaries and hypothesis tests alongside visualizations, ExploriPy might be a good choice.\n",
    "\n",
    "**Here are some additional tips for using automated EDA libraries:**\n",
    "\n",
    "- **Don't rely solely on automation:** While these libraries are helpful, don't overlook the importance of critically evaluating the generated reports and visualizations. Use them as a starting point for further exploration.\n",
    "- **Understand the data:** Regardless of the library, it's crucial to have a basic understanding of the data and its context to interpret the automated insights effectively.\n",
    "- **Combine with manual exploration:** Use these libraries alongside manual techniques like data cleaning, correlation analysis, and domain knowledge for a more comprehensive EDA approach.\n",
    "\n",
    "By effectively using these libraries, you can streamline the initial stages of EDA, saving time and allowing you to focus on more in-depth analysis and model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danish\\AppData\\Roaming\\Python\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import libreres\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ydata_profiling as ydp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset:  77%|███████▋  | 17/22 [00:01<00:00, 11.47it/s, Calculate auto correlation]   C:\\Users\\Danish\\AppData\\Roaming\\Python\\Python39\\site-packages\\ydata_profiling\\model\\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'could not convert string to float: 'no'')\n",
      "  warnings.warn(\n",
      "Summarize dataset:  88%|████████▊ | 36/41 [00:07<00:01,  3.39it/s, Missing diagram heatmap]   C:\\Users\\Danish\\AppData\\Roaming\\Python\\Python39\\site-packages\\seaborn\\matrix.py:260: FutureWarning: Format strings passed to MaskedConstant are ignored, but in future may error or produce different behavior\n",
      "  annotation = (\"{:\" + self.fmt + \"}\").format(val)\n",
      "C:\\Users\\Danish\\AppData\\Roaming\\Python\\Python39\\site-packages\\ydata_profiling\\model\\missing.py:78: UserWarning: There was an attempt to generate the Heatmap missing values diagrams, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(missing_diagrams={\"Heatmap\": False}`)\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'could not convert string to float: '--'')\n",
      "  warnings.warn(\n",
      "Summarize dataset: 100%|██████████| 41/41 [00:07<00:00,  5.41it/s, Completed]               \n",
      "Generate report structure: 100%|██████████| 1/1 [00:06<00:00,  6.45s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 125.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# ydata profiling report \n",
    "profile  = ydp.ProfileReport(df)\n",
    "profile.to_file(output_file=\"./outputs/ydata_titanic.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do it on our Pak Population Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop = pd.read_csv('../day_8\\sub-division_population_of_pakistan.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset:  82%|████████▏ | 23/28 [00:00<00:00, 56.02it/s, Calculate auto correlation]                  C:\\Users\\Danish\\AppData\\Roaming\\Python\\Python39\\site-packages\\ydata_profiling\\model\\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'could not convert string to float: 'BAHAWALPUR DIVISION'')\n",
      "  warnings.warn(\n",
      "Summarize dataset: 100%|██████████| 319/319 [01:03<00:00,  5.03it/s, Completed]                                                     \n",
      "Generate report structure: 100%|██████████| 1/1 [00:14<00:00, 14.43s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:15<00:00, 15.36s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s]\n"
     ]
    }
   ],
   "source": [
    "profile  = ydp.ProfileReport(df_pop)\n",
    "profile.to_file(output_file=\"./outputs/ydata_pak_population.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assighnment download two datasets from google dataset and do ydata_profiling on them and what you know about this dataset why that happend in this dataset?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
