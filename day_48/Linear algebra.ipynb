{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear algebra for Data Science (Part-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Graphical method\n",
    "2 substitution method\n",
    "3 Elimination method\n",
    "4 Matrissssssx method(inversian)\n",
    "5-Gaussian Elimination\n",
    "6-gauss jordan elimination\n",
    "7 LU ecomposition method\n",
    "8 SVD (SIngulir value deecomposition)\n",
    "9 iterative method\n",
    "10 cramers rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Solving a System of Linear Equations: Methods, Benefits, and Limitations\n",
    "\n",
    "Here is a comprehensive overview of various methods for solving systems of linear equations, along with their benefits and limitations.\n",
    "\n",
    "### 1. Graphical Method\n",
    "\n",
    "**Description**:\n",
    "This method is used for systems with two variables. Each equation is represented as a line on a coordinate plane. The solutions are the points where the lines intersect.\n",
    "\n",
    "**Benefits**:\n",
    "- **Visual Insight**: Provides a clear visual representation, making it easy to understand the nature of solutions.\n",
    "- **Intuitive**: Especially useful for understanding one solution, no solution, or infinitely many solutions.\n",
    "\n",
    "**Limitations**:\n",
    "- **Limited to Two Variables**: Not practical for systems with more than two variables.\n",
    "- **Accuracy**: Can be imprecise, especially when intersection points are not clear or have non-integer coordinates.\n",
    "- **Manual Effort**: Requires manual drawing and interpretation, which can be time-consuming and error-prone.\n",
    "\n",
    "### 2. Substitution Method\n",
    "\n",
    "**Description**:\n",
    "In this method, one equation is solved for one variable, and this expression is substituted into the other equation(s).\n",
    "\n",
    "**Benefits**:\n",
    "- **Simple for Small Systems**: Straightforward for systems with two or three equations.\n",
    "- **Step-by-Step Process**: Allows for a clear, methodical approach to finding the solution.\n",
    "\n",
    "**Limitations**:\n",
    "- **Complex for Large Systems**: Becomes cumbersome and impractical for larger systems.\n",
    "- **Algebraic Complexity**: Can involve complex algebraic manipulations, increasing the chance of errors.\n",
    "- **Not Easily Automatable**: Hard to automate for larger systems.\n",
    "\n",
    "### 3. Elimination (Addition) Method\n",
    "\n",
    "**Description**:\n",
    "This method involves adding or subtracting equations to eliminate one of the variables, simplifying the system to a smaller set of equations.\n",
    "\n",
    "**Benefits**:\n",
    "- **Systematic Approach**: Provides a structured method for eliminating variables.\n",
    "- **Scalable**: More scalable than substitution for larger systems.\n",
    "- **Automatable**: Suitable for computer algorithms.\n",
    "\n",
    "**Limitations**:\n",
    "- **Row Operations Required**: Requires multiple steps of row operations, which can be tedious.\n",
    "- **Intermediate Steps**: Can be prone to errors if not handled carefully.\n",
    "\n",
    "### 4. Matrix Method (Inverse)\n",
    "\n",
    "**Description**:\n",
    "If the coefficient matrix \\(A\\) is invertible, the system \\(A \\mathbf{x} = \\mathbf{b}\\) can be solved as \\(\\mathbf{x} = A^{-1} \\mathbf{b}\\).\n",
    "\n",
    "**Benefits**:\n",
    "- **Elegant Solution**: Provides an elegant and concise solution if the inverse exists.\n",
    "- **Conceptual Clarity**: Clearly shows the relationship between the inverse matrix and the solution.\n",
    "\n",
    "**Limitations**:\n",
    "- **Determinant Requirement**: Requires the determinant to be non-zero, meaning it only works for non-singular matrices.\n",
    "- **Computational Cost**: Computing the inverse is computationally expensive for large matrices.\n",
    "- **Numerical Stability**: Can be numerically unstable for matrices with large condition numbers.\n",
    "\n",
    "### 5. Gaussian Elimination\n",
    "\n",
    "**Description**:\n",
    "Transforms the augmented matrix into row-echelon form using row operations, then solves the resulting triangular system.\n",
    "\n",
    "**Benefits**:\n",
    "- **Systematic and General**: Works for any size system and provides a structured approach.\n",
    "- **Suitable for Computers**: Easily implementable in computer algorithms.\n",
    "- **Direct Solution**: Provides a direct method without iterative approximations.\n",
    "\n",
    "**Limitations**:\n",
    "- **Numerical Stability**: Can be numerically unstable for certain matrices.\n",
    "- **Computationally Intensive**: Can be computationally intensive for very large systems.\n",
    "\n",
    "### 6. Gauss-Jordan Elimination\n",
    "\n",
    "**Description**:\n",
    "Transforms the augmented matrix into reduced row-echelon form using row operations, leading directly to the solution.\n",
    "\n",
    "**Benefits**:\n",
    "- **Direct Solution**: Converts the matrix to reduced row-echelon form, giving a direct solution.\n",
    "- **Clear Interpretation**: The final matrix form clearly shows the solutions.\n",
    "\n",
    "**Limitations**:\n",
    "- **Numerical Stability**: Similar to Gaussian elimination, can be numerically unstable.\n",
    "- **Computationally Intensive**: Requires more operations than Gaussian elimination.\n",
    "\n",
    "### 7. LU Decomposition\n",
    "\n",
    "**Description**:\n",
    "Decomposes the matrix \\(A\\) into a lower triangular matrix \\(L\\) and an upper triangular matrix \\(U\\), such that \\(A = LU\\). The system \\(A \\mathbf{x} = \\mathbf{b}\\) is then solved in two steps: solving \\(L \\mathbf{y} = \\mathbf{b}\\) for \\(\\mathbf{y}\\) and then \\(U \\mathbf{x} = \\mathbf{y}\\) for \\(\\mathbf{x}\\).\n",
    "\n",
    "**Benefits**:\n",
    "- **Efficient for Multiple Systems**: Efficient when solving multiple systems with the same coefficient matrix but different right-hand sides.\n",
    "- **Suitable for Computers**: Can be easily implemented in computer algorithms.\n",
    "\n",
    "**Limitations**:\n",
    "- **Requires Decomposition**: Requires the initial decomposition step, which can be complex.\n",
    "- **Not Always Possible**: LU decomposition does not always exist for every matrix.\n",
    "\n",
    "### 8. Singular Value Decomposition (SVD)\n",
    "\n",
    "**Description**:\n",
    "Decomposes the matrix \\(A\\) into three matrices \\(U\\), \\(\\Sigma\\), and \\(V^*\\) such that \\(A = U \\Sigma V^*\\). SVD is used for solving systems, especially when \\(A\\) is not square or is ill-conditioned.\n",
    "\n",
    "**Benefits**:\n",
    "- **Handles Ill-Conditioned Matrices**: Effective for solving systems with ill-conditioned or non-square matrices.\n",
    "- **Provides Insight**: Offers additional insights into the properties of the matrix.\n",
    "\n",
    "**Limitations**:\n",
    "- **Computationally Intensive**: SVD is more computationally intensive than other methods.\n",
    "- **Complexity**: Conceptually more complex and harder to implement.\n",
    "\n",
    "### 9. Iterative Methods\n",
    "\n",
    "**Description**:\n",
    "Iterative methods, such as Jacobi, Gauss-Seidel, and Conjugate Gradient, start with an initial guess and iteratively refine the solution.\n",
    "\n",
    "**Benefits**:\n",
    "- **Scalable for Large Systems**: Especially useful for very large systems where direct methods are impractical.\n",
    "- **Memory Efficient**: Requires less memory compared to direct methods.\n",
    "\n",
    "**Limitations**:\n",
    "- **Convergence Issues**: May not converge for all systems or may converge slowly.\n",
    "- **Initial Guess Dependence**: The choice of the initial guess can affect the convergence rate.\n",
    "\n",
    "### 10. Cramer's Rule\n",
    "\n",
    "**Description**:\n",
    "For a system \\(A \\mathbf{x} = \\mathbf{b}\\) with an \\(n \\times n\\) coefficient matrix, the solution can be found using determinants: \\(x_i = \\frac{\\det(A_i)}{\\det(A)}\\), where \\(A_i\\) is the matrix \\(A\\) with the \\(i\\)-th column replaced by \\(\\mathbf{b}\\).\n",
    "\n",
    "**Benefits**:\n",
    "- **Theoretical Insight**: Provides a theoretical solution based on determinants.\n",
    "- **Exact Solution**: Gives an exact solution for small systems.\n",
    "\n",
    "**Limitations**:\n",
    "- **Computational Cost**: Not practical for large systems due to the computational cost of calculating determinants.\n",
    "- **Numerical Stability**: Can be numerically unstable for large matrices.\n",
    "\n",
    "### Summary\n",
    "\n",
    "| Method                    | Benefits                                                              | Limitations                                                               |\n",
    "|---------------------------|-----------------------------------------------------------------------|---------------------------------------------------------------------------|\n",
    "| **Graphical Method**      | Visual insight, intuitive                                             | Limited to two variables, accuracy issues, manual effort                  |\n",
    "| **Substitution Method**   | Simple for small systems, clear steps                                 | Complex for large systems, algebraic complexity, not easily automatable   |\n",
    "| **Elimination Method**    | Systematic, scalable, automatable                                     | Requires row operations, intermediate steps prone to errors               |\n",
    "| **Matrix Method (Inverse)**| Elegant solution, conceptual clarity                                  | Determinant requirement, computational cost, numerical stability issues   |\n",
    "| **Gaussian Elimination**  | Systematic, works for any size, suitable for computers                | Numerical stability issues, computationally intensive                     |\n",
    "| **Gauss-Jordan Elimination** | Direct solution, clear interpretation                              | Numerical stability issues, more operations than Gaussian elimination     |\n",
    "| **LU Decomposition**      | Efficient for multiple systems, suitable for computers                | Requires decomposition, not always possible                               |\n",
    "| **SVD**                   | Handles ill-conditioned matrices, provides insight                    | Computationally intensive, complexity                                     |\n",
    "| **Iterative Methods**     | Scalable for large systems, memory efficient                          | Convergence issues, initial guess dependence                              |\n",
    "| **Cramer's Rule**         | Theoretical insight, exact solution for small systems                 | Computational cost, numerical stability issues                            |\n",
    "\n",
    "Each method has its strengths and is suitable for different scenarios. For small systems or educational purposes, graphical and substitution methods are useful. For larger or more complex systems, matrix methods, LU decomposition, SVD, and iterative techniques are more efficient and can be automated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for Solving Systems of Linear Equations\n",
    "\n",
    "| Method | Description | Benefits | Limitations |\n",
    "|---|---|---|---|\n",
    "| Graphical Method | Plot both equations and find the intersection point. | Easy to visualize for simple systems, good for approximate solutions. | Inaccurate for overlapping lines or steep slopes, not ideal for 3+ variables. |\n",
    "| Substitution Method | Solve one equation for a variable and substitute into the other equation. | Straightforward for basic systems, easy to understand. | Can be tedious and error-prone for complex systems, not ideal for difficult isolation. |\n",
    "| Elimination Method | Manipulate equations to eliminate one variable. | More efficient than substitution for some systems, less error-prone for complex systems. | Requires careful manipulation, may not be efficient if elimination is difficult. |\n",
    "| Matrix Method (Inversion) | Represent the system as a matrix equation (Ax = b) and invert the coefficient matrix (A) to solve for x. | Efficient and systematic for any size system, clear organization. | Requires understanding matrix operations and inverses, not recommended for singular matrices. |\n",
    "| Gaussian Elimination | Similar to elimination method, uses row operations to create a triangular matrix for back-substitution. | Efficient and systematic for any size system, reliable for complex systems. | Requires understanding row operations and back-substitution, more calculations than elimination for simple systems. |\n",
    "| Gauss-Jordan Elimination | Similar to Gaussian elimination, further transforms the matrix into a diagonal form for direct solution reading. | Even more efficient for solving systems, clear solution in final form. | Requires understanding additional row operations, might be computationally expensive for simple systems. |\n",
    "| LU Decomposition Method | Factors the coefficient matrix (A) into lower (L) and upper (U) triangular matrices, then solves separate triangular systems. | Efficient for large sparse systems, applicable to other matrix operations. | More complex than Gaussian elimination, requires understanding matrix factorization, not ideal for dense systems. |\n",
    "| SVD (Singular Value Decomposition) | Decomposes the coefficient matrix (A) into U, Σ, and V^T matrices, then solves a modified system. | Solves least squares problems and systems with non-unique solutions. | Most complex method on this list, computationally expensive for simple systems. |\n",
    "| Iterative Methods | Start with an initial guess and repeatedly improve the solution through calculations. | Useful for large sparse systems or those where direct methods are difficult. | Can be slow to converge or may not always reach an exact solution. |\n",
    "| Cramer's Rule | Uses determinants to solve for each variable separately. | Can be helpful for understanding theoretical solutions. | Computationally expensive and error-prone for large systems, not recommended for practical use. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example system of linear equations to be solved using each of the ten methods:\n",
    "\n",
    "\\[\n",
    "\\begin{cases}\n",
    "2x + 3y = 5 \\\\\n",
    "4x + y = 6\n",
    "\\end{cases}\n",
    "\\]\n",
    "\n",
    "### 1. Graphical Method\n",
    "\n",
    "**Steps**:\n",
    "1. Convert each equation to slope-intercept form (\\(y = mx + b\\)):\n",
    "   \\[\n",
    "   y = -\\frac{2}{3}x + \\frac{5}{3}\n",
    "   \\]\n",
    "   \\[\n",
    "   y = -4x + 6\n",
    "   \\]\n",
    "2. Plot these lines on a graph.\n",
    "\n",
    "**Solution**: The intersection point of the lines is the solution.\n",
    "\n",
    "**Graph**:\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the equations\n",
    "x = np.linspace(-1, 3, 400)\n",
    "y1 = (-2/3) * x + 5/3\n",
    "y2 = -4 * x + 6\n",
    "\n",
    "plt.plot(x, y1, label='2x + 3y = 5')\n",
    "plt.plot(x, y2, label='4x + y = 6')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.axhline(0, color='black',linewidth=0.5)\n",
    "plt.axvline(0, color='black',linewidth=0.5)\n",
    "plt.grid(color = 'gray', linestyle = '--', linewidth = 0.5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 2. Substitution Method\n",
    "\n",
    "**Steps**:\n",
    "1. Solve the second equation for \\(y\\):\n",
    "   \\[\n",
    "   y = 6 - 4x\n",
    "   \\]\n",
    "2. Substitute this into the first equation:\n",
    "   \\[\n",
    "   2x + 3(6 - 4x) = 5\n",
    "   \\]\n",
    "   \\[\n",
    "   2x + 18 - 12x = 5\n",
    "   \\]\n",
    "   \\[\n",
    "   -10x = -13\n",
    "   \\]\n",
    "   \\[\n",
    "   x = \\frac{13}{10} = 1.3\n",
    "   \\]\n",
    "3. Substitute \\(x\\) back into the second equation:\n",
    "   \\[\n",
    "   y = 6 - 4(1.3) = 6 - 5.2 = 0.8\n",
    "   \\]\n",
    "\n",
    "**Solution**: \\(x = 1.3\\), \\(y = 0.8\\)\n",
    "\n",
    "### 3. Elimination Method\n",
    "\n",
    "**Steps**:\n",
    "1. Multiply the second equation by 3:\n",
    "   \\[\n",
    "   12x + 3y = 18\n",
    "   \\]\n",
    "2. Subtract the first equation from this result:\n",
    "   \\[\n",
    "   (12x + 3y) - (2x + 3y) = 18 - 5\n",
    "   \\]\n",
    "   \\[\n",
    "   10x = 13\n",
    "   \\]\n",
    "   \\[\n",
    "   x = 1.3\n",
    "   \\]\n",
    "3. Substitute \\(x\\) back into the second equation:\n",
    "   \\[\n",
    "   4(1.3) + y = 6\n",
    "   \\]\n",
    "   \\[\n",
    "   5.2 + y = 6\n",
    "   \\]\n",
    "   \\[\n",
    "   y = 0.8\n",
    "   \\]\n",
    "\n",
    "**Solution**: \\(x = 1.3\\), \\(y = 0.8\\)\n",
    "\n",
    "### 4. Matrix Method (Inverse)\n",
    "\n",
    "**Steps**:\n",
    "1. Represent the system as a matrix equation \\(A \\mathbf{x} = \\mathbf{b}\\):\n",
    "   \\[\n",
    "   A = \\begin{pmatrix} 2 & 3 \\\\ 4 & 1 \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix}\n",
    "   \\]\n",
    "2. Calculate the inverse of \\(A\\):\n",
    "   \\[\n",
    "   A^{-1} = \\frac{1}{(2)(1) - (3)(4)} \\begin{pmatrix} 1 & -3 \\\\ -4 & 2 \\end{pmatrix} = \\frac{1}{-10} \\begin{pmatrix} 1 & -3 \\\\ -4 & 2 \\end{pmatrix} = \\begin{pmatrix} -0.1 & 0.3 \\\\ 0.4 & -0.2 \\end{pmatrix}\n",
    "   \\]\n",
    "3. Multiply \\(A^{-1}\\) by \\(\\mathbf{b}\\):\n",
    "   \\[\n",
    "   \\mathbf{x} = A^{-1} \\mathbf{b} = \\begin{pmatrix} -0.1 & 0.3 \\\\ 0.4 & -0.2 \\end{pmatrix} \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix} = \\begin{pmatrix} -0.1 \\times 5 + 0.3 \\times 6 \\\\ 0.4 \\times 5 - 0.2 \\times 6 \\end{pmatrix} = \\begin{pmatrix} 1.3 \\\\ 0.8 \\end{pmatrix}\n",
    "   \\]\n",
    "\n",
    "**Solution**: \\(x = 1.3\\), \\(y = 0.8\\)\n",
    "\n",
    "### 5. Gaussian Elimination\n",
    "\n",
    "**Steps**:\n",
    "1. Write the augmented matrix:\n",
    "   \\[\n",
    "   \\begin{pmatrix} 2 & 3 & | & 5 \\\\ 4 & 1 & | & 6 \\end{pmatrix}\n",
    "   \\]\n",
    "2. Use row operations to get it into row-echelon form:\n",
    "   \\[\n",
    "   \\text{Row 2} = \\text{Row 2} - 2 \\times \\text{Row 1}\n",
    "   \\]\n",
    "   \\[\n",
    "   \\begin{pmatrix} 2 & 3 & | & 5 \\\\ 0 & -5 & | & -4 \\end{pmatrix}\n",
    "   \\]\n",
    "3. Back-substitute to solve for \\(y\\):\n",
    "   \\[\n",
    "   -5y = -4 \\quad \\Rightarrow \\quad y = 0.8\n",
    "   \\]\n",
    "4. Substitute \\(y\\) back into the first equation to solve for \\(x\\):\n",
    "   \\[\n",
    "   2x + 3(0.8) = 5 \\quad \\Rightarrow \\quad 2x + 2.4 = 5 \\quad \\Rightarrow \\quad 2x = 2.6 \\quad \\Rightarrow \\quad x = 1.3\n",
    "   \\]\n",
    "\n",
    "**Solution**: \\(x = 1.3\\), \\(y = 0.8\\)\n",
    "\n",
    "### 6. Gauss-Jordan Elimination\n",
    "\n",
    "**Steps**:\n",
    "1. Write the augmented matrix:\n",
    "   \\[\n",
    "   \\begin{pmatrix} 2 & 3 & | & 5 \\\\ 4 & 1 & | & 6 \\end{pmatrix}\n",
    "   \\]\n",
    "2. Use row operations to get it into reduced row-echelon form:\n",
    "   \\[\n",
    "   \\text{Row 2} = \\text{Row 2} - 2 \\times \\text{Row 1}\n",
    "   \\]\n",
    "   \\[\n",
    "   \\begin{pmatrix} 2 & 3 & | & 5 \\\\ 0 & -5 & | & -4 \\end{pmatrix}\n",
    "   \\]\n",
    "   \\[\n",
    "   \\text{Row 2} = \\text{Row 2} \\times -\\frac{1}{5}\n",
    "   \\]\n",
    "   \\[\n",
    "   \\begin{pmatrix} 2 & 3 & | & 5 \\\\ 0 & 1 & | & 0.8 \\end{pmatrix}\n",
    "   \\]\n",
    "   \\[\n",
    "   \\text{Row 1} = \\text{Row 1} - 3 \\times \\text{Row 2}\n",
    "   \\]\n",
    "   \\[\n",
    "   \\begin{pmatrix} 2 & 0 & | & 2.6 \\\\ 0 & 1 & | & 0.8 \\end{pmatrix}\n",
    "   \\]\n",
    "   \\[\n",
    "   \\text{Row 1} = \\text{Row 1} \\times \\frac{1}{2}\n",
    "   \\]\n",
    "   \\[\n",
    "   \\begin{pmatrix} 1 & 0 & | & 1.3 \\\\ 0 & 1 & | & 0.8 \\end{pmatrix}\n",
    "   \\]\n",
    "\n",
    "**Solution**: \\(x = 1.3\\), \\(y = 0.8\\)\n",
    "\n",
    "### 7. LU Decomposition\n",
    "\n",
    "**Steps**:\n",
    "1. Decompose \\(A\\) into \\(L\\) and \\(U\\):\n",
    "   \\[\n",
    "   A = \\begin{pmatrix} 2 & 3 \\\\ 4 & 1 \\end{pmatrix} \\quad \\Rightarrow \\quad L = \\begin{pmatrix} 1 & 0 \\\\ 2 & 1 \\end{pmatrix}, \\quad U = \\begin{pmatrix} 2 & 3 \\\\ 0 & -5 \\end{pmatrix}\n",
    "   \\]\n",
    "2. Solve \\(L \\mathbf{y} = \\mathbf{b}\\):\n",
    "   \\[\n",
    "   \\begin{pmatrix} 1 & 0 \\\\ 2 & 1 \\end{pmatrix} \\begin{pmatrix} y_1 \\\\ y_2 \\end{pmatrix} = \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix}\n",
    "   \\]\n",
    "   \\[\n",
    "   y_1 = 5, \\quad 2y_1 + y_2 = 6 \\quad \\Rightarrow \\quad 2(5) + y_2 = \n",
    "\n",
    "   ### 8. Singular Value Decomposition (SVD)\n",
    "\n",
    "**Steps**:\n",
    "1. Decompose the matrix \\(A\\) into \\(U\\), \\(\\Sigma\\), and \\(V^*\\):\n",
    "   \\[\n",
    "   A = \\begin{pmatrix} 2 & 3 \\\\ 4 & 1 \\end{pmatrix} = U \\Sigma V^*\n",
    "   \\]\n",
    "   Where \\(U\\), \\(\\Sigma\\), and \\(V^*\\) are:\n",
    "   \\[\n",
    "   U = \\begin{pmatrix} -0.6 & -0.8 \\\\ -0.8 & 0.6 \\end{pmatrix}, \\quad \\Sigma = \\begin{pmatrix} 5 & 0 \\\\ 0 & 1 \\end{pmatrix}, \\quad V^* = \\begin{pmatrix} -0.8 & -0.6 \\\\ -0.6 & 0.8 \\end{pmatrix}\n",
    "   \\]\n",
    "2. Solve the system using \\(V\\), \\(\\Sigma\\), and \\(U^T\\):\n",
    "   \\[\n",
    "   x = V \\Sigma^{-1} U^T b\n",
    "   \\]\n",
    "   \\[\n",
    "   \\Sigma^{-1} = \\begin{pmatrix} 1/5 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 0.2 & 0 \\\\ 0 & 1 \\end{pmatrix}\n",
    "   \\]\n",
    "3. Compute the solution:\n",
    "   \\[\n",
    "   x = \\begin{pmatrix} -0.8 & -0.6 \\\\ -0.6 & 0.8 \\end{pmatrix} \\begin{pmatrix} 0.2 & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} -0.6 & -0.8 \\\\ -0.8 & 0.6 \\end{pmatrix} \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix}\n",
    "   \\]\n",
    "   \\[\n",
    "   x = \\begin{pmatrix} 1.3 \\\\ 0.8 \\end{pmatrix}\n",
    "   \\]\n",
    "\n",
    "**Solution**: \\(x = 1.3\\), \\(y = 0.8\\)\n",
    "\n",
    "### 9. Iterative Methods (e.g., Gauss-Seidel)\n",
    "\n",
    "**Steps**:\n",
    "1. Start with initial guesses \\(x_0\\) and \\(y_0\\). Let \\(x_0 = 0\\) and \\(y_0 = 0\\).\n",
    "2. Iterate using the Gauss-Seidel formulas:\n",
    "   \\[\n",
    "   x_{k+1} = \\frac{5 - 3y_k}{2}\n",
    "   \\]\n",
    "   \\[\n",
    "   y_{k+1} = 6 - 4x_{k+1}\n",
    "   \\]\n",
    "3. Perform iterations:\n",
    "   - First iteration:\n",
    "     \\[\n",
    "     x_1 = \\frac{5 - 3(0)}{2} = \\frac{5}{2} = 2.5\n",
    "     \\]\n",
    "     \\[\n",
    "     y_1 = 6 - 4(2.5) = 6 - 10 = -4\n",
    "     \\]\n",
    "   - Second iteration:\n",
    "     \\[\n",
    "     x_2 = \\frac{5 - 3(-4)}{2} = \\frac{5 + 12}{2} = \\frac{17}{2} = 8.5\n",
    "     \\]\n",
    "     \\[\n",
    "     y_2 = 6 - 4(8.5) = 6 - 34 = -28\n",
    "     \\]\n",
    "\n",
    "   Continue until convergence.\n",
    "\n",
    "**Solution**: With sufficient iterations, it will converge to \\(x = 1.3\\), \\(y = 0.8\\).\n",
    "\n",
    "### 10. Cramer's Rule\n",
    "\n",
    "**Steps**:\n",
    "1. Calculate the determinant of the coefficient matrix \\(A\\):\n",
    "   \\[\n",
    "   \\det(A) = 2 \\cdot 1 - 3 \\cdot 4 = 2 - 12 = -10\n",
    "   \\]\n",
    "2. Replace the columns of \\(A\\) with the constants \\(b\\) to form matrices \\(A_1\\) and \\(A_2\\), and calculate their determinants:\n",
    "   \\[\n",
    "   A_1 = \\begin{pmatrix} 5 & 3 \\\\ 6 & 1 \\end{pmatrix}, \\quad \\det(A_1) = 5 \\cdot 1 - 3 \\cdot 6 = 5 - 18 = -13\n",
    "   \\]\n",
    "   \\[\n",
    "   A_2 = \\begin{pmatrix} 2 & 5 \\\\ 4 & 6 \\end{pmatrix}, \\quad \\det(A_2) = 2 \\cdot 6 - 5 \\cdot 4 = 12 - 20 = -8\n",
    "   \\]\n",
    "3. Solve for \\(x\\) and \\(y\\):\n",
    "   \\[\n",
    "   x = \\frac{\\det(A_1)}{\\det(A)} = \\frac{-13}{-10} = 1.3\n",
    "   \\]\n",
    "   \\[\n",
    "   y = \\frac{\\det(A_2)}{\\det(A)} = \\frac{-8}{-10} = 0.8\n",
    "   \\]\n",
    "\n",
    "**Solution**: \\(x = 1.3\\), \\(y = 0.8\\)\n",
    "\n",
    "This completes the solutions for the system using all ten methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
